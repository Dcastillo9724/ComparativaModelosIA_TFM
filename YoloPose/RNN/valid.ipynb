{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 person, 168.2ms\n",
      "Speed: 6.0ms preprocess, 168.2ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def put_text_with_background(image, text, position, font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=0.8, color=(255, 255, 255), thickness=2, bg_color=(0, 0, 0)):\n",
    "    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    x, y = position\n",
    "    cv2.rectangle(image, (x, y - text_height - 10), (x + text_width, y + baseline), bg_color, -1)  # Draw background rectangle\n",
    "    cv2.putText(image, text, position, font, font_scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def process_frame(frame, model, scaler_X, encoder, modelYolo):\n",
    "    alto_original, ancho_original = frame.shape[:2]\n",
    "    nuevo_alto = 1100  # Nueva altura deseada\n",
    "    nuevo_ancho = int((nuevo_alto / alto_original) * ancho_original)\n",
    "    frame = cv2.resize(frame, (nuevo_ancho, nuevo_alto))\n",
    "\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = modelYolo(image)\n",
    "\n",
    "    keypoints = results[0].keypoints.data.numpy().tolist()[0]\n",
    "\n",
    "    if len(keypoints) == 17:\n",
    "        # Extraer ángulos y distancias relevantes\n",
    "        left_shoulder = keypoints[5]\n",
    "        right_shoulder = keypoints[6]\n",
    "        left_elbow = keypoints[7]\n",
    "        right_elbow = keypoints[8]\n",
    "        left_wrist = keypoints[9]\n",
    "        right_wrist = keypoints[10]\n",
    "        left_hip = keypoints[11]\n",
    "        right_hip = keypoints[12]\n",
    "        left_knee = keypoints[13]\n",
    "        right_knee = keypoints[14]\n",
    "        left_ankle = keypoints[15]\n",
    "        right_ankle = keypoints[16]\n",
    "\n",
    "        # Ejemplo de ángulos\n",
    "        left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "        left_shoulder_angle = calculate_angle(left_hip, left_shoulder, left_elbow)\n",
    "        right_shoulder_angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "        left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "        right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "        \n",
    "        features = np.array(keypoints).flatten().tolist()\n",
    "\n",
    "        X = scaler_X.transform(np.array(features).reshape(1, -1))\n",
    "        X = X[:, :, np.newaxis]\n",
    "\n",
    "        predictions = model.predict(X)\n",
    "\n",
    "        predicciones_continuas = predictions[0][0]\n",
    "        prediccion_clase = encoder.inverse_transform(np.argmax(predictions[1], axis=1))\n",
    "\n",
    "        features_video = [left_elbow_angle, right_elbow_angle, left_shoulder_angle, right_shoulder_angle, left_knee_angle, right_knee_angle]\n",
    "\n",
    "        porcentaje_diferencia = 0.25\n",
    "        caracteristicas = [\"Angulo del codo izquierdo\", \"Angulo del codo derecho\", \"Angulo del hombro izquierdo\", \"Angulo del hombro derecho\", \"Angulo de la rodilla izquierda\", \"Angulo de la rodilla derecha\"]\n",
    "\n",
    "        array1 = np.array(predicciones_continuas)\n",
    "        array2 = np.array(features_video)\n",
    "        relacion = np.abs(1 - (array1 / array2))\n",
    "        errores = [caracteristicas[i] for i in range(len(relacion)) if porcentaje_diferencia < relacion[i] < (1 - porcentaje_diferencia)]\n",
    "\n",
    "        annotated_image = results[0].plot()\n",
    "  \n",
    "        clase_predicha = prediccion_clase[0]\n",
    "        porcentaje_prediccion = np.max(predictions[1]) * 100\n",
    "        texto_clasificacion = f'Clasificacion: {clase_predicha} - Probabilidad: {porcentaje_prediccion:.2f}%'\n",
    "        put_text_with_background(annotated_image, texto_clasificacion, (50, 70), font_scale=0.8, bg_color=(0, 0, 0))\n",
    "\n",
    "        if len(errores) > 0:\n",
    "            for i, error in enumerate(errores):\n",
    "                desplazamiento_vertical = 120 + (i * 30)\n",
    "                put_text_with_background(annotated_image, f'Error en : {error}', (50, desplazamiento_vertical), font_scale=0.8, bg_color=(0, 0, 0))\n",
    "\n",
    "        return annotated_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "def analyze_path(file_path, model, scaler_X, encoder, modelYolo):\n",
    "    if file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "        cap = cv2.VideoCapture(file_path)\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            annotated_frame = process_frame(frame, model, scaler_X, encoder, modelYolo)\n",
    "            cv2.imshow('Frame', cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    elif file_path.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "        frame = cv2.imread(file_path)\n",
    "        annotated_frame = process_frame(frame, model, scaler_X, encoder, modelYolo)\n",
    "        rgb_image = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow('Image', rgb_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Formato de archivo no soportado\")\n",
    "\n",
    "# Cargar el modelo y las clases\n",
    "ruta_actual = os.getcwd()\n",
    "carpeta_mediapipe = os.path.dirname(ruta_actual)\n",
    "ruta_raiz = os.path.dirname(carpeta_mediapipe)\n",
    "\n",
    "ruta_dataset = os.path.join(ruta_raiz, 'Data Set')\n",
    "ruta_archivo = os.path.join(ruta_dataset, 'test_image_3.jpg')  # Cambia esta ruta a la ruta del archivo que desees analizar\n",
    "ruta_npy = os.path.join(ruta_actual, 'datos', 'classes.npy')\n",
    "ruta_scaler = os.path.join(ruta_actual, 'datos', 'scaler_X.pkl')\n",
    "ruta_modelo = os.path.join(ruta_actual, 'model', 'exercise_model.h5')\n",
    "\n",
    "# Cargar el modelo y scaler\n",
    "model = load_model(ruta_modelo)\n",
    "scaler_X = joblib.load(ruta_scaler)\n",
    "\n",
    "classes = np.load(ruta_npy, allow_pickle=True)\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = classes\n",
    "\n",
    "modelYolo = YOLO(\"yolov8n-pose.pt\")\n",
    "\n",
    "# Realizar el análisis en la ruta dada\n",
    "analyze_path(ruta_archivo, model, scaler_X, encoder, modelYolo)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Unir_TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
