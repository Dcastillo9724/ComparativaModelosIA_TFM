{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from openpose import pyopenpose as op\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuración de OpenPose\n",
    "params = {\n",
    "    \"model_folder\": \"openpose/models/\",\n",
    "    \"net_resolution\": \"-1x368\"\n",
    "}\n",
    "opWrapper = op.WrapperPython()\n",
    "opWrapper.configure(params)\n",
    "opWrapper.start()\n",
    "\n",
    "def extract_keypoints_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    keypoints_list = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        datum = op.Datum()\n",
    "        datum.cvInputData = frame\n",
    "        opWrapper.emplaceAndPop([datum])\n",
    "        keypoints = datum.poseKeypoints\n",
    "        if keypoints is not None and len(keypoints) > 0:\n",
    "            keypoints_list.append(keypoints[0])\n",
    "    cap.release()\n",
    "    return keypoints_list\n",
    "\n",
    "def preprocess_keypoints(keypoints):\n",
    "    keypoints = np.array(keypoints)\n",
    "    max_val = np.max(keypoints, axis=(0, 1))\n",
    "    min_val = np.min(keypoints, axis=(0, 1))\n",
    "    normalized_keypoints = (keypoints - min_val) / (max_val - min_val)\n",
    "    flattened_keypoints = normalized_keypoints.reshape(keypoints.shape[0], -1)\n",
    "    return flattened_keypoints\n",
    "\n",
    "def create_dataset(video_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    exercise_labels = {\"sentadilla\": 0, \"dominadas\": 1, \"elevaciones_laterales\": 2, \"peso_muerto\": 3, \"plancha\": 4, \"press_banca\": 5, \"press_militar\": 6}\n",
    "    for exercise in exercise_labels.keys():\n",
    "        exercise_dir = os.path.join(video_dir, exercise)\n",
    "        for video_file in os.listdir(exercise_dir):\n",
    "            video_path = os.path.join(exercise_dir, video_file)\n",
    "            keypoints = extract_keypoints_from_video(video_path)\n",
    "            preprocessed_keypoints = preprocess_keypoints(keypoints)\n",
    "            for kp in preprocessed_keypoints:\n",
    "                data.append(kp)\n",
    "                labels.append(exercise_labels[exercise])\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Crear el dataset\n",
    "video_dir = \"videos\"\n",
    "X, y = create_dataset(video_dir)\n",
    "\n",
    "# Convertir las etiquetas a one-hot encoding\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir y compilar el modelo\n",
    "model = Sequential([\n",
    "    Conv1D(64, 3, activation='relu', input_shape=(X.shape[1], X.shape[2])),\n",
    "    Dropout(0.5),\n",
    "    Conv1D(128, 3, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Matriz de Confusión\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=exercise_labels.keys(), yticklabels=exercise_labels.keys())\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Calcular MAE, MSE, RMSE, R2, y Precisión\n",
    "mae = mean_absolute_error(y_true_classes, y_pred_classes)\n",
    "mse = mean_squared_error(y_true_classes, y_pred_classes)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true_classes, y_pred_classes)\n",
    "precision = accuracy_score(y_true_classes, y_pred_classes)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R2: {r2}')\n",
    "print(f'Precision: {precision}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
