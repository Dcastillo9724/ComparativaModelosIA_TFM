{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando fold 1...\n",
      "Epoch 1/50\n",
      "\u001b[1m499/900\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 7210.8940 - salida_clase_accuracy: 0.2088 - salidas_continuas_mae: 60.4643"
     ]
    }
   ],
   "source": [
    "# Definir rutas\n",
    "ruta_actual = os.getcwd()\n",
    "carpeta_mediapipe = os.path.dirname(ruta_actual)\n",
    "ruta_raiz = os.path.dirname(carpeta_mediapipe)\n",
    "\n",
    "ruta_npy = os.path.join(ruta_actual, 'datos', 'classes.npy')\n",
    "ruta_scaler = os.path.join(ruta_actual, 'datos', 'scaler_X.pkl')\n",
    "ruta_modelo = os.path.join(ruta_actual, 'model', 'exercise_model.h5')\n",
    "ruta_csv = os.path.join(carpeta_mediapipe, 'Datos_Videos_Pose', 'pose_data.csv')\n",
    "\n",
    "# Cargar el dataset\n",
    "data = pd.read_csv(ruta_csv)\n",
    "\n",
    "# Preparar entradas (Keypoints)\n",
    "num_keypoints = 33 * 3\n",
    "X = data.iloc[:, :num_keypoints].values\n",
    "\n",
    "# Las siguientes 11 columnas incluyen:\n",
    "# 10 características continuas (ángulos, distancias) + 1 tipo de ejercicio (última columna)\n",
    "y_continuas = data.iloc[:, num_keypoints:(data.shape[1] - 1)].values\n",
    "y_clase = data.iloc[:, -1].values\n",
    "\n",
    "# Codificar la etiqueta del tipo de ejercicio\n",
    "encoder = LabelEncoder()\n",
    "y_clase_encoded = encoder.fit_transform(y_clase)\n",
    "num_clases = len(encoder.classes_)\n",
    "\n",
    "# Normalizar las entradas\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Reshape para LSTM\n",
    "X_scaled = X_scaled[:, :, np.newaxis]  # Añadir una dimensión para el LSTM\n",
    "\n",
    "# Definir función para crear el modelo\n",
    "def create_model(input_shape, num_clases, learning_rate=0.001):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Capas LSTM con Dropout\n",
    "    x = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(input_layer)\n",
    "\n",
    "    # Salidas continuas (10 características)\n",
    "    salidas_continuas = Dense(10, activation='linear', name='salidas_continuas')(x)\n",
    "\n",
    "    # Salida de tipo de ejercicio (multiclase)\n",
    "    salida_clase = Dense(num_clases, activation='softmax', name='salida_clase')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=[salidas_continuas, salida_clase])\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={\n",
    "                      'salidas_continuas': 'mean_squared_error',\n",
    "                      'salida_clase': 'sparse_categorical_crossentropy'\n",
    "                  },\n",
    "                  metrics={\n",
    "                      'salidas_continuas': 'mae',\n",
    "                      'salida_clase': 'accuracy'\n",
    "                  })\n",
    "    return model\n",
    "\n",
    "# Inicializar KFold y métricas\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "all_loss = []\n",
    "all_mae = []\n",
    "all_mse = []\n",
    "all_rmse = []\n",
    "all_r2 = []\n",
    "all_accuracy = []\n",
    "all_precision = []\n",
    "all_recall = []\n",
    "all_f1 = []\n",
    "\n",
    "# Matrices para almacenar la historia del entrenamiento\n",
    "n_epochs = 50  # Número de épocas\n",
    "all_train_loss = np.full((n_splits, n_epochs), np.nan)  \n",
    "all_val_loss = np.full((n_splits, n_epochs), np.nan)\n",
    "all_train_accuracy = np.full((n_splits, n_epochs), np.nan)\n",
    "all_val_accuracy = np.full((n_splits, n_epochs), np.nan)\n",
    "\n",
    "# Validación cruzada\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_scaled)):\n",
    "    print(f\"Entrenando fold {fold + 1}...\")\n",
    "\n",
    "    X_train_fold, X_val_fold = X_scaled[train_index], X_scaled[val_index]\n",
    "    y_continuas_train_fold, y_continuas_val_fold = y_continuas[train_index], y_continuas[val_index]\n",
    "    y_clase_train_fold, y_clase_val_fold = y_clase_encoded[train_index], y_clase_encoded[val_index]\n",
    "\n",
    "    model = create_model(input_shape=(X_train_fold.shape[1], X_train_fold.shape[2]), num_clases=num_clases, learning_rate=0.0005)\n",
    "\n",
    "    tensorboard_callback = TensorBoard(log_dir=os.path.join(ruta_actual, 'logs', f'fold_{fold + 1}'), histogram_freq=1)\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "    history = model.fit(X_train_fold, {'salidas_continuas': y_continuas_train_fold, 'salida_clase': y_clase_train_fold},\n",
    "                        validation_data=(X_val_fold, {'salidas_continuas': y_continuas_val_fold, 'salida_clase': y_clase_val_fold}),\n",
    "                        epochs=n_epochs, batch_size=32, callbacks=[tensorboard_callback, early_stopping_callback, reduce_lr_callback])\n",
    "\n",
    "    # Almacenar la historia del entrenamiento como matrices NumPy\n",
    "    epochs_completed = len(history.history['loss'])\n",
    "    all_train_loss[fold, :epochs_completed] = history.history['loss']\n",
    "    all_val_loss[fold, :epochs_completed] = history.history['val_loss']\n",
    "    all_train_accuracy[fold, :epochs_completed] = history.history['salida_clase_accuracy']\n",
    "    all_val_accuracy[fold, :epochs_completed] = history.history['val_salida_clase_accuracy']\n",
    "\n",
    "    # Evaluar el modelo en el conjunto de validación\n",
    "    scores = model.evaluate(X_val_fold, {'salidas_continuas': y_continuas_val_fold, 'salida_clase': y_clase_val_fold})\n",
    "    print(f\"Fold {fold + 1}: Loss={scores[0]}, MAE={scores[2]}, Accuracy={scores[1]}\")\n",
    "\n",
    "    # Calcular métricas adicionales para las salidas continuas\n",
    "    y_pred_continuas = model.predict(X_val_fold)[0]\n",
    "    mae = mean_absolute_error(y_continuas_val_fold, y_pred_continuas)\n",
    "    mse = mean_squared_error(y_continuas_val_fold, y_pred_continuas)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = 1 - mse / np.var(y_continuas_val_fold)\n",
    "\n",
    "    all_loss.append(scores[0])\n",
    "    all_mae.append(mae)\n",
    "    all_mse.append(mse)\n",
    "    all_rmse.append(rmse)\n",
    "    all_r2.append(r2)\n",
    "    all_accuracy.append(scores[1])\n",
    "\n",
    "    # Calcular métricas de clasificación\n",
    "    y_pred_clase = np.argmax(model.predict(X_val_fold)[1], axis=1)\n",
    "    precision = precision_score(y_clase_val_fold, y_pred_clase, average='weighted')\n",
    "    recall = recall_score(y_clase_val_fold, y_pred_clase, average='weighted')\n",
    "    f1 = f1_score(y_clase_val_fold, y_pred_clase, average='weighted')\n",
    "\n",
    "    all_precision.append(precision)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "    # Imprimir matriz de confusión\n",
    "    cm = confusion_matrix(y_clase_val_fold, y_pred_clase, labels=np.unique(y_clase_val_fold))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=encoder.classes_)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "    plt.title(f'Matriz de Confusión ')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promediar las historias del entrenamiento\n",
    "mean_train_loss = np.mean(all_train_loss, axis=0)\n",
    "mean_val_loss = np.mean(all_val_loss, axis=0)\n",
    "mean_train_accuracy = np.mean(all_train_accuracy, axis=0)\n",
    "mean_val_accuracy = np.mean(all_val_accuracy, axis=0)\n",
    "\n",
    "# Graficar los promedios\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Promedio de Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(mean_train_loss, label='Training Loss Promedio')\n",
    "plt.plot(mean_val_loss, label='Validation Loss Promedio')\n",
    "plt.title('Promedio de Loss durante el Entrenamiento y la Validación')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Promedio de Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(mean_train_accuracy, label='Training Accuracy Promedio')\n",
    "plt.plot(mean_val_accuracy, label='Validation Accuracy Promedio')\n",
    "plt.title('Promedio de Accuracy durante el Entrenamiento y la Validación')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Imprimir métricas promedio de todos los folds\n",
    "print(\"\\nMétricas promedio de todos los folds:\")\n",
    "print(f\"Loss: {np.mean(all_loss)}\")\n",
    "print(f\"MAE: {np.mean(all_mae)}\")\n",
    "print(f\"MSE: {np.mean(all_mse)}\")\n",
    "print(f\"RMSE: {np.mean(all_rmse)}\")\n",
    "print(f\"R^2: {np.mean(all_r2)}\")\n",
    "print(f\"Accuracy: {np.mean(all_accuracy)}\")\n",
    "print(f\"Precisión: {np.mean(all_precision)}\")\n",
    "print(f\"Recall: {np.mean(all_recall)}\")\n",
    "print(f\"F1-Score: {np.mean(all_f1)}\")\n",
    "\n",
    "# Guardar el modelo\n",
    "model.save(ruta_modelo)\n",
    "joblib.dump(scaler_X, ruta_scaler)\n",
    "np.save(ruta_npy, encoder.classes_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Unir_TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
