{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision opencv-python\n",
    "# Para AlphaPose, sigue las instrucciones de instalaci贸n en el repositorio oficial:\n",
    "# https://github.com/MVIG-SJTU/AlphaPose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from alphapose.utils.transforms import get_func_heatmap_to_coord\n",
    "from alphapose.models import builder\n",
    "from alphapose.utils.config import update_config\n",
    "from alphapose.utils.pPose_nms import pose_nms\n",
    "from alphapose.utils.presets import SimpleTransform\n",
    "\n",
    "# Configuraci贸n de AlphaPose\n",
    "cfg = update_config('alphapose/config.yaml')\n",
    "pose_model = builder.build_sppe(cfg.MODEL, preset_cfg=cfg.DATA_PRESET)\n",
    "pose_model.load_state_dict(torch.load('path/to/alphapose/model.pth', map_location='cpu'))\n",
    "pose_model.eval()\n",
    "\n",
    "def extract_keypoints_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    keypoints_list = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Preprocesamiento del frame\n",
    "        input_img, meta = SimpleTransform()(frame)\n",
    "        with torch.no_grad():\n",
    "            output = pose_model(input_img)\n",
    "            # Postprocesamiento\n",
    "            keypoints, scores = get_func_heatmap_to_coord(output)\n",
    "            keypoints_list.append(keypoints)\n",
    "    cap.release()\n",
    "    return keypoints_list\n",
    "\n",
    "# Ejemplo de uso\n",
    "video_path = \"video\"\n",
    "keypoints = extract_keypoints_from_video(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_keypoints(keypoints):\n",
    "    keypoints = np.array(keypoints)\n",
    "    max_val = np.max(keypoints, axis=(0, 1))\n",
    "    min_val = np.min(keypoints, axis=(0, 1))\n",
    "    normalized_keypoints = (keypoints - min_val) / (max_val - min_val)\n",
    "    flattened_keypoints = normalized_keypoints.reshape(keypoints.shape[0], -1)\n",
    "    return flattened_keypoints\n",
    "\n",
    "preprocessed_keypoints = preprocess_keypoints(keypoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(video_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    exercise_labels = {\"sentadilla\": 0, \"dominadas\": 1, \"elevaciones_laterales\": 2, \"peso_muerto\": 3, \"plancha\": 4, \"press_banca\": 5, \"press_militar\": 6}\n",
    "    for exercise in exercise_labels.keys():\n",
    "        exercise_dir = os.path.join(video_dir, exercise)\n",
    "        for video_file in os.listdir(exercise_dir):\n",
    "            video_path = os.path.join(exercise_dir, video_file)\n",
    "            keypoints = extract_keypoints_from_video(video_path)\n",
    "            preprocessed_keypoints = preprocess_keypoints(keypoints)\n",
    "            for kp in preprocessed_keypoints:\n",
    "                data.append(kp)\n",
    "                labels.append(exercise_labels[exercise])\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "video_dir = \"videos\"\n",
    "X, y = create_dataset(video_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convertir las etiquetas a one-hot encoding\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir y compilar el modelo DNN\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Matriz de Confusi贸n\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=exercise_labels.keys(), yticklabels=exercise_labels.keys())\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Calcular MAE, MSE, RMSE, R2, y Precisi贸n\n",
    "mae = mean_absolute_error(y_true_classes, y_pred_classes)\n",
    "mse = mean_squared_error(y_true_classes, y_pred_classes)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true_classes, y_pred_classes)\n",
    "precision = accuracy_score(y_true_classes, y_pred_classes)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R2: {r2}')\n",
    "print(f'Precision: {precision}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
